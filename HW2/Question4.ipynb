{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an index map to uniquely identify each cell in the grid with a single number\n",
    "index_map = [[(i + 5*j) for i in range(5)] for j in range(5)]\n",
    "\n",
    "#LHS of the bellman equations\n",
    "lhs = np.zeros((25 * 4,25))\n",
    "\n",
    "#RHS of the bellman equation\n",
    "rhs = np.zeros((25 * 4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that returns the next state and reward\n",
    "#The function takes as input the current state and the action performed\n",
    "def get_next_state_and_reward(row, col, action):\n",
    "    #The following part of the code handles the special cases where the reward is 10 and 5\n",
    "    if row == 0:\n",
    "        if col == 1:\n",
    "            reward = 10\n",
    "            state = 21\n",
    "            return state, reward\n",
    "        if col == 3:\n",
    "            reward = 5\n",
    "            state = 13\n",
    "            return state, reward\n",
    "        \n",
    "    #All other cases are uniform. The action variable denotes up,left,down or right\n",
    "    x = col + action[0]\n",
    "    y = row + action[1]\n",
    "    state = index_map[row][col]\n",
    "    \n",
    "    #If the object doesn't fall of the grid, the reward is 0 and state is updated\n",
    "    if (x > -1 and x < 5) and (y > - 1 and y < 5):\n",
    "        state = index_map[y][x]\n",
    "        reward = 0\n",
    "    else:\n",
    "        #This is for when the object falls of, the state is the same and reward is -1\n",
    "        reward = -1\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = [[-1,0],[1,0],[0,-1],[0,1]]\n",
    "actions = {0 : \"Left\", 1 : \"Right\", 2 : \"Up\", 3 : \"Down\" }\n",
    "#For this part, optimality equation is non linear, \n",
    "#because of the max variable present, so we can setup \n",
    "#Ax >= b inequality for all the possible actions and then solve\n",
    "\n",
    "#This gives us 100 inequalities in 25 variables to solve\n",
    "#Every action has its own reward and next state value \n",
    "#THe optimal state value function will be greater than or equal to all these values and hence the inequality holds\n",
    "\n",
    "#Iterate over all cells\n",
    "for row in range(5):\n",
    "    for col in range(5):\n",
    "        cur = index_map[row][col]\n",
    "        action_counter = 0\n",
    "        for action in allowed:\n",
    "            next_, reward = get_next_state_and_reward(row, col, action) \n",
    "            lhs[cur*4 + action_counter][cur] -= 1.0\n",
    "            lhs[cur*4 + action_counter][next_] += 0.9  #0.9 is the gamma value\n",
    "            rhs[cur*4 + action_counter] -= reward#0.25 denotes equal probability\n",
    "            action_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V* - Optimal Value Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22. , 24.4, 22. , 19.4, 17.5],\n",
       "       [19.8, 22. , 19.8, 17.8, 16. ],\n",
       "       [17.8, 19.8, 17.8, 16. , 14.4],\n",
       "       [16. , 17.8, 16. , 14.4, 13. ],\n",
       "       [14.4, 16. , 14.4, 13. , 11.7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln = np.asarray(optimize.linprog(np.ones(25), lhs, rhs).x)\n",
    "soln = np.around(soln,1)\n",
    "soln = soln.reshape((5,5))\n",
    "soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_star = soln.reshape(25,1)\n",
    "pi = np.zeros((25,4))\n",
    "for row in range(5):\n",
    "    for col in range(5):\n",
    "        cur = index_map[row][col]\n",
    "        pi_cur = pi[cur]\n",
    "        q_temp = []\n",
    "        pi_new = np.zeros(4)\n",
    "        action_counter = 0\n",
    "        for action in allowed:\n",
    "            next_, reward = get_next_state_and_reward(row, col, action)\n",
    "            q_temp.append(v_star[next_][0])\n",
    "        optim_actions = np.argwhere(q_temp == np.amax(q_temp))\n",
    "        optim_actions = optim_actions.flatten().tolist()\n",
    "        num = len(optim_actions)\n",
    "        pi_new[optim_actions] = 1.0/num\n",
    "        pi[cur] = pi_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Right ', 'Left Right Up Down ', 'Left ', 'Left Right Up Down ', 'Left '],\n",
       " ['Right Up ', 'Up ', 'Left Up ', 'Left ', 'Left '],\n",
       " ['Right Up ', 'Up ', 'Left Up ', 'Left Up ', 'Left Up '],\n",
       " ['Right Up ', 'Up ', 'Left Up ', 'Left Up ', 'Left Up '],\n",
       " ['Right Up ', 'Up ', 'Left Up ', 'Left Up ', 'Left Up ']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = [[\"\" for i in range(5)] for j in range(5)]\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        cur = index_map[i][j]\n",
    "        fav_actions = pi[cur]\n",
    "        st = \"\"\n",
    "        for k in range(4):\n",
    "            if fav_actions[k] > 0:\n",
    "                st += actions[k] + \" \"\n",
    "        ans[i][j] = st\n",
    "ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
